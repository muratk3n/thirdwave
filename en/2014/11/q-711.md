# Q&A - 7/11

Question

I see tech, scientist people equally divided on AI doomsday scenarios. 

Which tech people?Â 

Most AI people, that is current researchers in the field, do not feel
an urgency about this issue. There are scientists who do, but I
believe most of them come from natural sciences / physics background,
or related fields. In such areas, especially high-energy physics you
are dealing with forces of nature that can go berserk in unexpected
directions. The goal is to tame them, use them, etc. It is dangerous
stuff... After all, that's where nuclear energy or A-bomb came from,
right? This culture has dominated the view of science for many
years. Combined with the industrial age whose structures dwarf the
individual reducing people (many workers) to mere automatons, a view
of science was formed that paints the field as 1) big 2) can go crazy
3) destroy the planet and humans alike.

AI is different. In this field the practitioners create the algorithms
from scratch, they are not trying to tame forces of nature. Yes there
are "biologically inspired" algorithms, but they are just that, an
"inspiration", not the thing itself. Even if it was, the end result is
data processing and decision making, not seperating the atom, or
shooting off lasers.

Looking at the list of people who support the AI calamity scenario can
prove this point.  Stephen Hawking: physicist. Elon Musk: his company
deals with high-energy combustion, propulsion, literally "rocket
science". Peter Thiel: an hi-tech investor (a very good one), but not
a practitioner in AI.

Note: all of the people above we respect, and agree with on many
issues btw.








at

November 07, 2014















